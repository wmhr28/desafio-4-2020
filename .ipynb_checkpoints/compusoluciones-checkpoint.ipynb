{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MARATONA BEHIND THE CODE 2020\n",
    "\n",
    "## DESAFIO 4 - CompuSoluciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este desafío, CompuSoluciones usará herramientas de IBM como Watson Studio (o Cloud Pack for Data) y Watson Machine Learning para construir un modelo de Machine Learning natural capaz de predecir la probabilidad de cumplimiento de pago.\n",
    "\n",
    "La idea esencial del Desafío 4 es crear un modelo basado en machine learning capaz de identificar el comportamiento financiero del asociado de negocio, permitiendo una probabilidad de cumplimiento o incumplimiento del crédito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación de Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: imbalanced-learn in c:\\users\\wm_herrera\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.23 in c:\\users\\wm_herrera\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.23.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in c:\\users\\wm_herrera\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\wm_herrera\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\wm_herrera\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.17.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\wm_herrera\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in c:\\users\\wm_herrera\\anaconda3\\lib\\site-packages (0.23.2)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in c:\\users\\wm_herrera\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\wm_herrera\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\wm_herrera\\anaconda3\\lib\\site-packages (from scikit-learn) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\wm_herrera\\anaconda3\\lib\\site-packages (from scikit-learn) (1.17.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si desea utilizar la biblioteca ** xgboost **, instale la versión 0.71.\n",
    "#!pip install xgboost==0.71 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargando el dataset csv desde Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "#!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/dataset/master/reto-4-compu-train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EFECTIVO</th>\n",
       "      <th>CXC</th>\n",
       "      <th>INVENTARIO</th>\n",
       "      <th>EQ_OFICINA</th>\n",
       "      <th>EQ_TRANSPORTE</th>\n",
       "      <th>TERRENOS_Y_CONSTRUCCIONES</th>\n",
       "      <th>CXP</th>\n",
       "      <th>CONTRIBUCIONES_X_PAGAR</th>\n",
       "      <th>ANTICIPOS_CTE</th>\n",
       "      <th>CAP_SOCIAL</th>\n",
       "      <th>UTILIDADES_ACUMULADAS</th>\n",
       "      <th>UTILIDAD_O_PERDIDA</th>\n",
       "      <th>TOTAL_VENTAS</th>\n",
       "      <th>TOTAL_COMPRAS</th>\n",
       "      <th>UTILIDAD_BRUTA</th>\n",
       "      <th>TOTAL_GASTOS</th>\n",
       "      <th>OBJETIVO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.710800e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.237449e+06</td>\n",
       "      <td>2.947057e+05</td>\n",
       "      <td>8.812520e+06</td>\n",
       "      <td>4.547214e+07</td>\n",
       "      <td>239671.50090</td>\n",
       "      <td>1.257907e+06</td>\n",
       "      <td>2356497.733</td>\n",
       "      <td>-6.009930e+06</td>\n",
       "      <td>-6.816681e+06</td>\n",
       "      <td>41309820.53</td>\n",
       "      <td>6.872572e+07</td>\n",
       "      <td>6298390.104</td>\n",
       "      <td>1.505762e+07</td>\n",
       "      <td>Aceptado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.437098e+04</td>\n",
       "      <td>2.213116e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.335531e+05</td>\n",
       "      <td>4.000109e+05</td>\n",
       "      <td>8.491851e+06</td>\n",
       "      <td>1.573254e+07</td>\n",
       "      <td>94809.20697</td>\n",
       "      <td>6.708985e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.980962e+06</td>\n",
       "      <td>-3.342452e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.588274e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.085156e+07</td>\n",
       "      <td>Aceptado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.269987e+06</td>\n",
       "      <td>2.893119e+07</td>\n",
       "      <td>3.983352e+05</td>\n",
       "      <td>1.533061e+07</td>\n",
       "      <td>3.478673e+06</td>\n",
       "      <td>-1.393229e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>610814.63990</td>\n",
       "      <td>1.009937e+07</td>\n",
       "      <td>1444426.243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.026344e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.292337e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.680735e+06</td>\n",
       "      <td>Sospechoso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.092134e+05</td>\n",
       "      <td>1.145092e+07</td>\n",
       "      <td>9.577823e+06</td>\n",
       "      <td>1.068692e+06</td>\n",
       "      <td>1.302021e+06</td>\n",
       "      <td>1.379064e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.378928e+06</td>\n",
       "      <td>1236065.779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.567435e+06</td>\n",
       "      <td>76310275.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.323267e+07</td>\n",
       "      <td>Aceptado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.688669e+05</td>\n",
       "      <td>8.539206e+06</td>\n",
       "      <td>3.898283e+06</td>\n",
       "      <td>4.168733e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.297179e+05</td>\n",
       "      <td>7.620711e+06</td>\n",
       "      <td>116647.73960</td>\n",
       "      <td>1.798065e+06</td>\n",
       "      <td>3657339.603</td>\n",
       "      <td>7.702845e+05</td>\n",
       "      <td>-7.110320e+05</td>\n",
       "      <td>62901614.29</td>\n",
       "      <td>3.614260e+07</td>\n",
       "      <td>6850340.403</td>\n",
       "      <td>1.100048e+07</td>\n",
       "      <td>Aceptado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EFECTIVO           CXC    INVENTARIO    EQ_OFICINA  EQ_TRANSPORTE  \\\n",
       "0           NaN  7.710800e+06           NaN  1.237449e+06   2.947057e+05   \n",
       "1  7.437098e+04  2.213116e+06           NaN  1.335531e+05   4.000109e+05   \n",
       "2  5.269987e+06  2.893119e+07  3.983352e+05  1.533061e+07   3.478673e+06   \n",
       "3  9.092134e+05  1.145092e+07  9.577823e+06  1.068692e+06   1.302021e+06   \n",
       "4  9.688669e+05  8.539206e+06  3.898283e+06  4.168733e+05            NaN   \n",
       "\n",
       "   TERRENOS_Y_CONSTRUCCIONES           CXP  CONTRIBUCIONES_X_PAGAR  \\\n",
       "0               8.812520e+06  4.547214e+07            239671.50090   \n",
       "1               8.491851e+06  1.573254e+07             94809.20697   \n",
       "2              -1.393229e+07           NaN            610814.63990   \n",
       "3               1.379064e+06           NaN                     NaN   \n",
       "4              -6.297179e+05  7.620711e+06            116647.73960   \n",
       "\n",
       "   ANTICIPOS_CTE   CAP_SOCIAL  UTILIDADES_ACUMULADAS  UTILIDAD_O_PERDIDA  \\\n",
       "0   1.257907e+06  2356497.733          -6.009930e+06       -6.816681e+06   \n",
       "1   6.708985e+05          NaN          -7.980962e+06       -3.342452e+06   \n",
       "2   1.009937e+07  1444426.243                    NaN       -4.026344e+06   \n",
       "3   2.378928e+06  1236065.779                    NaN       -4.567435e+06   \n",
       "4   1.798065e+06  3657339.603           7.702845e+05       -7.110320e+05   \n",
       "\n",
       "   TOTAL_VENTAS  TOTAL_COMPRAS  UTILIDAD_BRUTA  TOTAL_GASTOS    OBJETIVO  \n",
       "0   41309820.53   6.872572e+07     6298390.104  1.505762e+07    Aceptado  \n",
       "1           NaN   3.588274e+07             NaN  1.085156e+07    Aceptado  \n",
       "2           NaN   3.292337e+08             NaN  8.680735e+06  Sospechoso  \n",
       "3   76310275.60            NaN             NaN  1.323267e+07    Aceptado  \n",
       "4   62901614.29   3.614260e+07     6850340.403  1.100048e+07    Aceptado  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'https://raw.githubusercontent.com/vanderlei-test/dataset/master/reto-4-compu-train.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9400 entries, 0 to 9399\n",
      "Data columns (total 17 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   EFECTIVO                   7986 non-null   float64\n",
      " 1   CXC                        7968 non-null   float64\n",
      " 2   INVENTARIO                 8000 non-null   float64\n",
      " 3   EQ_OFICINA                 7945 non-null   float64\n",
      " 4   EQ_TRANSPORTE              7988 non-null   float64\n",
      " 5   TERRENOS_Y_CONSTRUCCIONES  8038 non-null   float64\n",
      " 6   CXP                        7934 non-null   float64\n",
      " 7   CONTRIBUCIONES_X_PAGAR     8052 non-null   float64\n",
      " 8   ANTICIPOS_CTE              7976 non-null   float64\n",
      " 9   CAP_SOCIAL                 8036 non-null   float64\n",
      " 10  UTILIDADES_ACUMULADAS      7993 non-null   float64\n",
      " 11  UTILIDAD_O_PERDIDA         8031 non-null   float64\n",
      " 12  TOTAL_VENTAS               7941 non-null   float64\n",
      " 13  TOTAL_COMPRAS              7908 non-null   float64\n",
      " 14  UTILIDAD_BRUTA             7971 non-null   float64\n",
      " 15  TOTAL_GASTOS               7943 non-null   float64\n",
      " 16  OBJETIVO                   9400 non-null   object \n",
      "dtypes: float64(16), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "1  0  1\n",
       "2  1  0\n",
       "3  w  s"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx = pd.DataFrame({'a':[0,0,1,'w'], 'b':[0,1,0,'s']})\n",
    "dfx = dfx[(dfx.T != 0).any()]\n",
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.T != 0).any()]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acerca del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9400 entries, 0 to 9399\n",
      "Data columns (total 17 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   EFECTIVO                   7986 non-null   float64\n",
      " 1   CXC                        7968 non-null   float64\n",
      " 2   INVENTARIO                 8000 non-null   float64\n",
      " 3   EQ_OFICINA                 7945 non-null   float64\n",
      " 4   EQ_TRANSPORTE              7988 non-null   float64\n",
      " 5   TERRENOS_Y_CONSTRUCCIONES  8038 non-null   float64\n",
      " 6   CXP                        7934 non-null   float64\n",
      " 7   CONTRIBUCIONES_X_PAGAR     8052 non-null   float64\n",
      " 8   ANTICIPOS_CTE              7976 non-null   float64\n",
      " 9   CAP_SOCIAL                 8036 non-null   float64\n",
      " 10  UTILIDADES_ACUMULADAS      7993 non-null   float64\n",
      " 11  UTILIDAD_O_PERDIDA         8031 non-null   float64\n",
      " 12  TOTAL_VENTAS               7941 non-null   float64\n",
      " 13  TOTAL_COMPRAS              7908 non-null   float64\n",
      " 14  UTILIDAD_BRUTA             7971 non-null   float64\n",
      " 15  TOTAL_GASTOS               7943 non-null   float64\n",
      " 16  OBJETIVO                   9400 non-null   object \n",
      "dtypes: float64(16), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables son todas numericas. Solo nuestra variable TARGET (Prestamo aprobado o posible incumplimiento financiero) es the tipo float.\n",
    "\n",
    "La función describe() de abajo muestra varias estadisticas del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EFECTIVO</th>\n",
       "      <th>CXC</th>\n",
       "      <th>INVENTARIO</th>\n",
       "      <th>EQ_OFICINA</th>\n",
       "      <th>EQ_TRANSPORTE</th>\n",
       "      <th>TERRENOS_Y_CONSTRUCCIONES</th>\n",
       "      <th>CXP</th>\n",
       "      <th>CONTRIBUCIONES_X_PAGAR</th>\n",
       "      <th>ANTICIPOS_CTE</th>\n",
       "      <th>CAP_SOCIAL</th>\n",
       "      <th>UTILIDADES_ACUMULADAS</th>\n",
       "      <th>UTILIDAD_O_PERDIDA</th>\n",
       "      <th>TOTAL_VENTAS</th>\n",
       "      <th>TOTAL_COMPRAS</th>\n",
       "      <th>UTILIDAD_BRUTA</th>\n",
       "      <th>TOTAL_GASTOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.986000e+03</td>\n",
       "      <td>7.968000e+03</td>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>7.945000e+03</td>\n",
       "      <td>7.988000e+03</td>\n",
       "      <td>8.038000e+03</td>\n",
       "      <td>7.934000e+03</td>\n",
       "      <td>8.052000e+03</td>\n",
       "      <td>7.976000e+03</td>\n",
       "      <td>8.036000e+03</td>\n",
       "      <td>7.993000e+03</td>\n",
       "      <td>8.031000e+03</td>\n",
       "      <td>7.941000e+03</td>\n",
       "      <td>7.908000e+03</td>\n",
       "      <td>7.971000e+03</td>\n",
       "      <td>7.943000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.720915e+06</td>\n",
       "      <td>1.561073e+07</td>\n",
       "      <td>1.098941e+07</td>\n",
       "      <td>4.341284e+06</td>\n",
       "      <td>1.321588e+06</td>\n",
       "      <td>6.198420e+05</td>\n",
       "      <td>2.275234e+07</td>\n",
       "      <td>4.109997e+05</td>\n",
       "      <td>2.635145e+06</td>\n",
       "      <td>3.325138e+06</td>\n",
       "      <td>4.240122e+06</td>\n",
       "      <td>-2.090086e+06</td>\n",
       "      <td>1.017051e+08</td>\n",
       "      <td>1.211510e+08</td>\n",
       "      <td>1.702067e+07</td>\n",
       "      <td>1.620236e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.958844e+06</td>\n",
       "      <td>1.980334e+07</td>\n",
       "      <td>1.541956e+07</td>\n",
       "      <td>1.885512e+07</td>\n",
       "      <td>1.398674e+06</td>\n",
       "      <td>6.202347e+06</td>\n",
       "      <td>2.810091e+07</td>\n",
       "      <td>6.311683e+05</td>\n",
       "      <td>3.828127e+06</td>\n",
       "      <td>4.122756e+06</td>\n",
       "      <td>1.066916e+07</td>\n",
       "      <td>2.439421e+06</td>\n",
       "      <td>1.148423e+08</td>\n",
       "      <td>3.320798e+08</td>\n",
       "      <td>1.710116e+07</td>\n",
       "      <td>1.341951e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.591455e+03</td>\n",
       "      <td>3.282261e+01</td>\n",
       "      <td>5.019700e-02</td>\n",
       "      <td>2.974216e+02</td>\n",
       "      <td>1.698222e+02</td>\n",
       "      <td>-1.577708e+07</td>\n",
       "      <td>1.276200e+01</td>\n",
       "      <td>5.638191e+03</td>\n",
       "      <td>4.495763e+00</td>\n",
       "      <td>2.334091e+00</td>\n",
       "      <td>-4.029189e+07</td>\n",
       "      <td>-8.716171e+06</td>\n",
       "      <td>7.154203e+03</td>\n",
       "      <td>1.458903e+05</td>\n",
       "      <td>2.408107e+03</td>\n",
       "      <td>3.979024e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.874601e+05</td>\n",
       "      <td>2.362067e+06</td>\n",
       "      <td>9.281351e+05</td>\n",
       "      <td>1.769855e+05</td>\n",
       "      <td>3.433503e+05</td>\n",
       "      <td>-3.874056e+06</td>\n",
       "      <td>3.711720e+06</td>\n",
       "      <td>1.113298e+05</td>\n",
       "      <td>3.813363e+05</td>\n",
       "      <td>5.629920e+05</td>\n",
       "      <td>-3.025772e+06</td>\n",
       "      <td>-3.824858e+06</td>\n",
       "      <td>2.303181e+07</td>\n",
       "      <td>1.214764e+07</td>\n",
       "      <td>4.836037e+06</td>\n",
       "      <td>6.104123e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.112329e+05</td>\n",
       "      <td>8.255125e+06</td>\n",
       "      <td>4.810330e+06</td>\n",
       "      <td>6.529255e+05</td>\n",
       "      <td>8.630635e+05</td>\n",
       "      <td>1.828932e+06</td>\n",
       "      <td>1.286143e+07</td>\n",
       "      <td>2.288855e+05</td>\n",
       "      <td>1.235872e+06</td>\n",
       "      <td>1.870131e+06</td>\n",
       "      <td>4.119952e+06</td>\n",
       "      <td>-1.629044e+06</td>\n",
       "      <td>6.309045e+07</td>\n",
       "      <td>3.473485e+07</td>\n",
       "      <td>1.181114e+07</td>\n",
       "      <td>1.272461e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.432613e+06</td>\n",
       "      <td>2.160462e+07</td>\n",
       "      <td>1.474278e+07</td>\n",
       "      <td>2.430901e+06</td>\n",
       "      <td>1.827559e+06</td>\n",
       "      <td>5.955197e+06</td>\n",
       "      <td>3.097250e+07</td>\n",
       "      <td>4.690705e+05</td>\n",
       "      <td>3.273238e+06</td>\n",
       "      <td>4.536913e+06</td>\n",
       "      <td>1.140550e+07</td>\n",
       "      <td>-7.368186e+03</td>\n",
       "      <td>1.378293e+08</td>\n",
       "      <td>1.007433e+08</td>\n",
       "      <td>2.352766e+07</td>\n",
       "      <td>2.260017e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.343603e+08</td>\n",
       "      <td>2.135761e+08</td>\n",
       "      <td>1.664338e+08</td>\n",
       "      <td>5.913821e+08</td>\n",
       "      <td>1.290365e+07</td>\n",
       "      <td>9.031323e+06</td>\n",
       "      <td>2.644946e+08</td>\n",
       "      <td>1.618323e+07</td>\n",
       "      <td>4.291686e+07</td>\n",
       "      <td>4.116688e+07</td>\n",
       "      <td>4.056842e+07</td>\n",
       "      <td>1.214191e+06</td>\n",
       "      <td>1.151511e+09</td>\n",
       "      <td>1.000136e+10</td>\n",
       "      <td>1.438985e+08</td>\n",
       "      <td>9.763166e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           EFECTIVO           CXC    INVENTARIO    EQ_OFICINA  EQ_TRANSPORTE  \\\n",
       "count  7.986000e+03  7.968000e+03  8.000000e+03  7.945000e+03   7.988000e+03   \n",
       "mean   1.720915e+06  1.561073e+07  1.098941e+07  4.341284e+06   1.321588e+06   \n",
       "std    5.958844e+06  1.980334e+07  1.541956e+07  1.885512e+07   1.398674e+06   \n",
       "min    2.591455e+03  3.282261e+01  5.019700e-02  2.974216e+02   1.698222e+02   \n",
       "25%    1.874601e+05  2.362067e+06  9.281351e+05  1.769855e+05   3.433503e+05   \n",
       "50%    5.112329e+05  8.255125e+06  4.810330e+06  6.529255e+05   8.630635e+05   \n",
       "75%    1.432613e+06  2.160462e+07  1.474278e+07  2.430901e+06   1.827559e+06   \n",
       "max    3.343603e+08  2.135761e+08  1.664338e+08  5.913821e+08   1.290365e+07   \n",
       "\n",
       "       TERRENOS_Y_CONSTRUCCIONES           CXP  CONTRIBUCIONES_X_PAGAR  \\\n",
       "count               8.038000e+03  7.934000e+03            8.052000e+03   \n",
       "mean                6.198420e+05  2.275234e+07            4.109997e+05   \n",
       "std                 6.202347e+06  2.810091e+07            6.311683e+05   \n",
       "min                -1.577708e+07  1.276200e+01            5.638191e+03   \n",
       "25%                -3.874056e+06  3.711720e+06            1.113298e+05   \n",
       "50%                 1.828932e+06  1.286143e+07            2.288855e+05   \n",
       "75%                 5.955197e+06  3.097250e+07            4.690705e+05   \n",
       "max                 9.031323e+06  2.644946e+08            1.618323e+07   \n",
       "\n",
       "       ANTICIPOS_CTE    CAP_SOCIAL  UTILIDADES_ACUMULADAS  UTILIDAD_O_PERDIDA  \\\n",
       "count   7.976000e+03  8.036000e+03           7.993000e+03        8.031000e+03   \n",
       "mean    2.635145e+06  3.325138e+06           4.240122e+06       -2.090086e+06   \n",
       "std     3.828127e+06  4.122756e+06           1.066916e+07        2.439421e+06   \n",
       "min     4.495763e+00  2.334091e+00          -4.029189e+07       -8.716171e+06   \n",
       "25%     3.813363e+05  5.629920e+05          -3.025772e+06       -3.824858e+06   \n",
       "50%     1.235872e+06  1.870131e+06           4.119952e+06       -1.629044e+06   \n",
       "75%     3.273238e+06  4.536913e+06           1.140550e+07       -7.368186e+03   \n",
       "max     4.291686e+07  4.116688e+07           4.056842e+07        1.214191e+06   \n",
       "\n",
       "       TOTAL_VENTAS  TOTAL_COMPRAS  UTILIDAD_BRUTA  TOTAL_GASTOS  \n",
       "count  7.941000e+03   7.908000e+03    7.971000e+03  7.943000e+03  \n",
       "mean   1.017051e+08   1.211510e+08    1.702067e+07  1.620236e+07  \n",
       "std    1.148423e+08   3.320798e+08    1.710116e+07  1.341951e+07  \n",
       "min    7.154203e+03   1.458903e+05    2.408107e+03  3.979024e+03  \n",
       "25%    2.303181e+07   1.214764e+07    4.836037e+06  6.104123e+06  \n",
       "50%    6.309045e+07   3.473485e+07    1.181114e+07  1.272461e+07  \n",
       "75%    1.378293e+08   1.007433e+08    2.352766e+07  2.260017e+07  \n",
       "max    1.151511e+09   1.000136e+10    1.438985e+08  9.763166e+07  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento y evaluación de un modelo de clasificación binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Transformación 1: excluir columnas del conjunto de datos\n",
    "\n",
    "Para la creación de una transformación de datos personalizada en scikit-learn, es necesario crear una clase con los métodos transform y fit. En el método de 'transform', se ejecutará la lógica de nuestra transformación.\n",
    "\n",
    "La siguiente celda muestra el código completo de una transformación DropColumns para eliminar columnas de un pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "# All sklearn Transforms must have the `transform` and `fit` methods\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Primero copiamos el dataframe de datos de entrada 'X'\n",
    "        data = X.copy()\n",
    "        # Devolvemos un nuevo dataframe de datos sin las columnas no deseadas\n",
    "        return data.drop(labels=self.columns, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropColumns(columns=[])\n"
     ]
    }
   ],
   "source": [
    "# Creación de instancias de una transformación DropColumns\n",
    "rm_columns = DropColumns(\n",
    "    columns=[]  # Esta transformación toma como parámetro una lista con los nombres de las columnas no deseadas\n",
    ")\n",
    "\n",
    "print(rm_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del conjunto de datos original: \n",
      "\n",
      "Index(['EFECTIVO', 'CXC', 'INVENTARIO', 'EQ_OFICINA', 'EQ_TRANSPORTE',\n",
      "       'TERRENOS_Y_CONSTRUCCIONES', 'CXP', 'CONTRIBUCIONES_X_PAGAR',\n",
      "       'ANTICIPOS_CTE', 'CAP_SOCIAL', 'UTILIDADES_ACUMULADAS',\n",
      "       'UTILIDAD_O_PERDIDA', 'TOTAL_VENTAS', 'TOTAL_COMPRAS', 'UTILIDAD_BRUTA',\n",
      "       'TOTAL_GASTOS', 'OBJETIVO'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Columnas del conjunto de datos después de la transformación ``DropColumns``: \n",
      "\n",
      "Index(['EFECTIVO', 'CXC', 'INVENTARIO', 'EQ_OFICINA', 'EQ_TRANSPORTE',\n",
      "       'TERRENOS_Y_CONSTRUCCIONES', 'CXP', 'CONTRIBUCIONES_X_PAGAR',\n",
      "       'ANTICIPOS_CTE', 'CAP_SOCIAL', 'UTILIDADES_ACUMULADAS',\n",
      "       'UTILIDAD_O_PERDIDA', 'TOTAL_VENTAS', 'TOTAL_COMPRAS', 'UTILIDAD_BRUTA',\n",
      "       'TOTAL_GASTOS', 'OBJETIVO'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Ver las columnas del conjunto de datos original\n",
    "print(\"Columnas del conjunto de datos original: \\n\")\n",
    "print(df.columns)\n",
    "\n",
    "# Aplicar la transformación ``DropColumns`` al conjunto de datos base\n",
    "rm_columns.fit(X=df)\n",
    "\n",
    "# Reconstruyendo un DataFrame de Pandas con el resultado de la transformación\n",
    "df2 = pd.DataFrame.from_records(\n",
    "    data=rm_columns.transform(\n",
    "        X=df\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Ver las columnas del conjunto de datos transformado\n",
    "print(\"\\n\\nColumnas del conjunto de datos después de la transformación ``DropColumns``: \\n\")\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación 2: estandarización de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición de features (Variables Independientes)\n",
    "\n",
    "En este * ejemplo * usaremos todas las columnas. (Usted debe decidir cuales variables utilizar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### División en 80% entrenamiento y 20% pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación 3: tratamiento de datos faltantes\n",
    "\n",
    "Para manejar los datos que faltan en nuestro conjunto de datos, ahora usaremos una transformación lista para usar de la biblioteca scikit-learn, llamada SimpleImputer.\n",
    "\n",
    "Esta transformación permite varias estrategias para el tratamiento de datos faltantes. La documentación oficial se puede encontrar en: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "\n",
    "En este ejemplo, simplemente haremos cero todos los valores faltante usted puede escoger otra estrategia ;)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleImputer(fill_value=0, strategy='constant')\n"
     ]
    }
   ],
   "source": [
    "# Crear un objeto ``SimpleImputer``\n",
    "si = SimpleImputer(\n",
    "    missing_values=np.nan,  # los valores que faltan son del tipo ``np.nan`` (Pandas estándar)\n",
    "    strategy='constant',  # la estrategia elegida es cambiar el valor faltante por una constante\n",
    "    fill_value=0,  # la constante que se usará para completar los valores faltantes es un int64 = 0\n",
    "    verbose=0,\n",
    "    copy=True\n",
    ")\n",
    "\n",
    "print(si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos antes de la transformación SimpleImputer: \n",
      "\n",
      "EFECTIVO                     1414\n",
      "CXC                          1432\n",
      "INVENTARIO                   1400\n",
      "EQ_OFICINA                   1455\n",
      "EQ_TRANSPORTE                1412\n",
      "TERRENOS_Y_CONSTRUCCIONES    1362\n",
      "CXP                          1466\n",
      "CONTRIBUCIONES_X_PAGAR       1348\n",
      "ANTICIPOS_CTE                1424\n",
      "CAP_SOCIAL                   1364\n",
      "UTILIDADES_ACUMULADAS        1407\n",
      "UTILIDAD_O_PERDIDA           1369\n",
      "TOTAL_VENTAS                 1459\n",
      "TOTAL_COMPRAS                1492\n",
      "UTILIDAD_BRUTA               1429\n",
      "TOTAL_GASTOS                 1457\n",
      "OBJETIVO                        0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Valores nulos en el conjunto de datos después de la transformación SimpleImputer: \n",
      "\n",
      "EFECTIVO                     0\n",
      "CXC                          0\n",
      "INVENTARIO                   0\n",
      "EQ_OFICINA                   0\n",
      "EQ_TRANSPORTE                0\n",
      "TERRENOS_Y_CONSTRUCCIONES    0\n",
      "CXP                          0\n",
      "CONTRIBUCIONES_X_PAGAR       0\n",
      "ANTICIPOS_CTE                0\n",
      "CAP_SOCIAL                   0\n",
      "UTILIDADES_ACUMULADAS        0\n",
      "UTILIDAD_O_PERDIDA           0\n",
      "TOTAL_VENTAS                 0\n",
      "TOTAL_COMPRAS                0\n",
      "UTILIDAD_BRUTA               0\n",
      "TOTAL_GASTOS                 0\n",
      "OBJETIVO                     0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver los datos faltantes del conjunto de datos antes de la primera transformación (df_data_2)\n",
    "print(\"Valores nulos antes de la transformación SimpleImputer: \\n\\n{}\\n\".format(df2.isnull().sum(axis = 0)))\n",
    "\n",
    "# Aplicamos el SimpleImputer ``si`` al conjunto de datos df_data_2 (resultado de la primera transformación)\n",
    "si.fit(X=df2)\n",
    "\n",
    "# Reconstrucción de un nuevo DataFrame de Pandas con el conjunto imputado (df_data_3)\n",
    "df3 = pd.DataFrame.from_records(\n",
    "    data=si.transform(\n",
    "        X=df2\n",
    "    ),  # el resultado SimpleImputer.transform (<< pandas dataframe >>) es lista lista\n",
    "    columns=df2.columns  # las columnas originales deben conservarse en esta transformación\n",
    ")\n",
    "\n",
    "# Ver los datos faltantes del conjunto de datos después de la segunda transformación (SimpleImputer) (df_data_3)\n",
    "print(\"\\n\\nValores nulos en el conjunto de datos después de la transformación SimpleImputer: \\n\\n{}\\n\".format(df3.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9400 entries, 0 to 9399\n",
      "Data columns (total 17 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   EFECTIVO                   9400 non-null   float64\n",
      " 1   CXC                        9400 non-null   float64\n",
      " 2   INVENTARIO                 9400 non-null   float64\n",
      " 3   EQ_OFICINA                 9400 non-null   float64\n",
      " 4   EQ_TRANSPORTE              9400 non-null   float64\n",
      " 5   TERRENOS_Y_CONSTRUCCIONES  9400 non-null   float64\n",
      " 6   CXP                        9400 non-null   float64\n",
      " 7   CONTRIBUCIONES_X_PAGAR     9400 non-null   float64\n",
      " 8   ANTICIPOS_CTE              9400 non-null   float64\n",
      " 9   CAP_SOCIAL                 9400 non-null   float64\n",
      " 10  UTILIDADES_ACUMULADAS      9400 non-null   float64\n",
      " 11  UTILIDAD_O_PERDIDA         9400 non-null   float64\n",
      " 12  TOTAL_VENTAS               9400 non-null   float64\n",
      " 13  TOTAL_COMPRAS              9400 non-null   float64\n",
      " 14  UTILIDAD_BRUTA             9400 non-null   float64\n",
      " 15  TOTAL_GASTOS               9400 non-null   float64\n",
      " 16  OBJETIVO                   9400 non-null   object \n",
      "dtypes: float64(16), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9400 entries, 0 to 9399\n",
      "Data columns (total 17 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   EFECTIVO                   9400 non-null   float64\n",
      " 1   CXC                        9400 non-null   float64\n",
      " 2   INVENTARIO                 9400 non-null   float64\n",
      " 3   EQ_OFICINA                 9400 non-null   float64\n",
      " 4   EQ_TRANSPORTE              9400 non-null   float64\n",
      " 5   TERRENOS_Y_CONSTRUCCIONES  9400 non-null   float64\n",
      " 6   CXP                        9400 non-null   float64\n",
      " 7   CONTRIBUCIONES_X_PAGAR     9400 non-null   float64\n",
      " 8   ANTICIPOS_CTE              9400 non-null   float64\n",
      " 9   CAP_SOCIAL                 9400 non-null   float64\n",
      " 10  UTILIDADES_ACUMULADAS      9400 non-null   float64\n",
      " 11  UTILIDAD_O_PERDIDA         9400 non-null   float64\n",
      " 12  TOTAL_VENTAS               9400 non-null   float64\n",
      " 13  TOTAL_COMPRAS              9400 non-null   float64\n",
      " 14  UTILIDAD_BRUTA             9400 non-null   float64\n",
      " 15  TOTAL_GASTOS               9400 non-null   float64\n",
      " 16  OBJETIVO                   9400 non-null   object \n",
      "dtypes: float64(16), object(1)\n",
      "memory usage: 1.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9400 entries, 0 to 9399\n",
      "Data columns (total 17 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   EFECTIVO                   9400 non-null   float64\n",
      " 1   CXC                        9400 non-null   float64\n",
      " 2   INVENTARIO                 9400 non-null   float64\n",
      " 3   EQ_OFICINA                 9400 non-null   float64\n",
      " 4   EQ_TRANSPORTE              9400 non-null   float64\n",
      " 5   TERRENOS_Y_CONSTRUCCIONES  9400 non-null   float64\n",
      " 6   CXP                        9400 non-null   float64\n",
      " 7   CONTRIBUCIONES_X_PAGAR     9400 non-null   float64\n",
      " 8   ANTICIPOS_CTE              9400 non-null   float64\n",
      " 9   CAP_SOCIAL                 9400 non-null   float64\n",
      " 10  UTILIDADES_ACUMULADAS      9400 non-null   float64\n",
      " 11  UTILIDAD_O_PERDIDA         9400 non-null   float64\n",
      " 12  TOTAL_VENTAS               9400 non-null   float64\n",
      " 13  TOTAL_COMPRAS              9400 non-null   float64\n",
      " 14  UTILIDAD_BRUTA             9400 non-null   float64\n",
      " 15  TOTAL_GASTOS               9400 non-null   float64\n",
      " 16  OBJETIVO                   9400 non-null   object \n",
      "dtypes: float64(16), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df3 = df3[(df3.T != 0).any()]\n",
    "df3.info()\n",
    "df3 = df3.drop_duplicates()\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 8))\n",
    "\n",
    "sns.countplot(ax=axes[0], x='OBJETIVO', data=df3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo las variables features y target (removed CXC and CXP)\n",
    "\n",
    "features = df3[\n",
    "    [\n",
    "        'EFECTIVO',\n",
    "        'INVENTARIO',\n",
    "        'EQ_OFICINA',\n",
    "        'EQ_TRANSPORTE',\n",
    "        'TERRENOS_Y_CONSTRUCCIONES',\n",
    "        'CONTRIBUCIONES_X_PAGAR',\n",
    "        'ANTICIPOS_CTE',\n",
    "        'CAP_SOCIAL',\n",
    "        'UTILIDADES_ACUMULADAS',\n",
    "        'UTILIDAD_O_PERDIDA',\n",
    "        'TOTAL_VENTAS',\n",
    "        'TOTAL_COMPRAS',\n",
    "        'UTILIDAD_BRUTA',\n",
    "        'TOTAL_GASTOS',\n",
    "    ]\n",
    "]\n",
    "target = df3[\"OBJETIVO\"]  ## No cambie la variable target!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x train 7520 , x test 1880\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=None)\n",
    "print(f\" x train {len(X_train)} , x test {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aceptado      7078\n",
       "Sospechoso     442\n",
       "Name: OBJETIVO, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'signature'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-372d74022955>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" x train {len(X_train)} , y_train {len(y_train)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcombine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\combine\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \"\"\"\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote_enn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote_tomek\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\combine\\_smote_enn.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseOverSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEditedNearestNeighbours\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_adasyn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mADASYN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_random_over_sampler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBorderlineSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeansSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMiniBatchKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                            FeatureAgglomeration)\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mk_means_\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mk_means\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMiniBatchKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdbscan_\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdbscan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbicluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSpectralBiclustering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpectralCoclustering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbirch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBirch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\dbscan_.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mClusterMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mignore_warnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\testing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unittest_backport\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTestCase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[0madditional_names_in_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'signature'"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)\n",
    "\n",
    "print(f\" x train {len(X_train)} , y_train {len(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenando un modelo ``DecisionTreeClassifier()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método para creacion de modelos basados en arbol de desición\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=3)\n",
    "model = dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Haciendo una predicción con el set de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = dtc.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizar la calidad del modelo a través de la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "group_names = ['Aprobado `Aceptado`', 'Refused `Sospechoso`', 'Refused `Aceptado`', 'Aprobado `Sospechoso`']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "accuracy  = np.trace(cf_matrix) / float(np.sum(cf_matrix))\n",
    "precision = cf_matrix[1,1] / sum(cf_matrix[:,1])\n",
    "recall    = cf_matrix[1,1] / sum(cf_matrix[1,:])\n",
    "f1_score  = 2*precision*recall / (precision + recall)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='')\n",
    "stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={}\".format(accuracy, precision, recall, f1_score)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label' + stats_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ¡ATENCIÓN! Su puntuación en este desafío de clasificación se basará en la puntuación F1 del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción del Pipeline completo para el encapsulamiento en WML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparando transformaciones personalizadas para cargar en WML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el reto 2 (Tortuga Code), se mostró cómo crear una transformación personalizada, declarando una clase Python con los métodos ``fit`` y ``transform``.\n",
    "\n",
    "    - Código de transformación personalizada DropColumns():\n",
    "    \n",
    "    from sklearn.base import BaseEstimator, TransformerMixin\n",
    "    # All sklearn Transforms must have the `transform` and `fit` methods\n",
    "    class DropColumns(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, columns):\n",
    "            self.columns = columns\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "        def transform(self, X):\n",
    "            # Primero copiamos el dataframe de entrada 'X' de entrada\n",
    "            data = X.copy()\n",
    "            # Devolvemos un nuevo marco de datos sin las columnas no deseadas\n",
    "            return data.drop(labels=self.columns, axis='columns')\n",
    "\n",
    "Para integrar estos tipos de transformaciones personalizadas con Pipelines en Watson Machine Learning, primero debe empaquetar su código personalizado como una biblioteca de Python. Esto se puede hacer fácilmente usando la herramienta *setuptools*.\n",
    "\n",
    "En el siguiente repositorio de git: https://github.com/vnderlev/sklearn_transforms tenemos todos los archivos necesarios para crear un paquete de Python, llamado **my_custom_sklearn_transforms**.\n",
    "Este paquete tiene la siguiente estructura de archivos:\n",
    "\n",
    "    /my_custom_sklearn_transforms.egg-info\n",
    "        dependency_links.txt\n",
    "        not-zip-safe\n",
    "        PKG-INFO\n",
    "        SOURCES.txt\n",
    "        top_level.txt\n",
    "    /my_custom_sklearn_transforms\n",
    "        __init__.py\n",
    "        sklearn_transformers.py\n",
    "    PKG-INFO\n",
    "    README.md\n",
    "    setup.cfg\n",
    "    setup.py\n",
    "    \n",
    "El archivo principal, que contendrá el código para nuestras transformaciones personalizadas, es el archivo **/my_custom_sklearn_transforms/sklearn_transformers.py**. Si accedes a él en el repositorio, notarás que contiene exactamente el mismo código declarado en el primer paso (la clase DropColumns).\n",
    "\n",
    "Si has declarado sus propias transformaciones (además de la DropColumn proporcionada), debes agregar todas las clases de esas transformaciones creadas en este mismo archivo. Para hacer esto, debes hacer fork de este repositorio (esto se puede hacer en la propia interfaz web de Github, haciendo clic en el botón como se muestra en la imagen a continuación) y agregue sus clases personalizadas al archivo **sklearn_transformers.py**.\n",
    "\n",
    "![alt text](https://i.imgur.com/2lZ4Ty2.png \"forking-a-repo\")\n",
    "\n",
    "Si solo hizo uso de la transformación proporcionada (DropColumns), puede omitir este paso de fork y continuar usando el paquete base provisto. :)\n",
    "\n",
    "Después de preparar su paquete de Python con sus transformaciones personalizadas, reemplace el enlace del repositorio de git en la celda a continuación y ejecútelo. Si no ha preparado ninguna transformación nueva, ejecute la celda con el enlace del repositorio ya proporcionado.\n",
    "\n",
    "<hr>\n",
    "    \n",
    "**OBSERVACIÓN**\n",
    "\n",
    "Si la ejecución de la celda a continuación devuelve un error de que el repositorio ya existe, ejecute:\n",
    "\n",
    "**!rm -r -f sklearn_transforms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Susbtituya el link de abajo por el link de su repositorio git (se es necesario)\n",
    "!git clone https://github.com/vnderlev/sklearn_transforms.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd sklearn_transforms\n",
    "!ls -ltr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para subir o código no WML, precisamos enviar um arquivo .zip com todo o código fonte, então iremos zipar o diretório clonado em seguida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!zip -r sklearn_transforms.zip sklearn_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el archivo zip de nuestro paquete cargado en el Kernel de este notebook, podemos utiliar la herramienta pip para instalarlo conforme a la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn_transforms.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos realizar la importación de nuestro paquiete personalizado en nuestro notabook!\n",
    "\n",
    "Vamos a importan la transformación DropColumns. Si usted posee otras transformaciones personalizadas, ahora es que debe importarlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_custom_sklearn_transforms.sklearn_transformers import DropColumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo el model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATENCIÓN, NO CAMBIE LA CELDA DE ABAJO O SU MODELO NO SERA EVALUADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_input = df[\n",
    "    [\n",
    "        'EFECTIVO',\n",
    "        'CXC',\n",
    "        'INVENTARIO',\n",
    "        'EQ_OFICINA',\n",
    "        'EQ_TRANSPORTE',\n",
    "        'TERRENOS_Y_CONSTRUCCIONES',\n",
    "        'CXP',\n",
    "        'CONTRIBUCIONES_X_PAGAR',\n",
    "        'ANTICIPOS_CTE',\n",
    "        'CAP_SOCIAL',\n",
    "        'UTILIDADES_ACUMULADAS',\n",
    "        'UTILIDAD_O_PERDIDA',\n",
    "        'TOTAL_VENTAS',\n",
    "        'TOTAL_COMPRAS',\n",
    "        'UTILIDAD_BRUTA',\n",
    "        'TOTAL_GASTOS',\n",
    "    ]\n",
    "]\n",
    "\n",
    "pipeline_target = df['OBJETIVO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de los datos en un set de entrenamiento y otro de prueba (PARA CREACION DEL PIPELINE)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pipeline_input,\n",
    "    pipeline_target,\n",
    "    test_size=0.3,\n",
    "    random_state=21233\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borrando las columnas del dataset original\n",
    "\n",
    "Debe elminiar todas las columnas que no esta usando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion de la Transformación Personalizada ``DropColumns``\n",
    "\n",
    "rm_columns = DropColumns(\n",
    "    columns=['CXC', 'CXP']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reemplazando con zeros en lugar de valores nulos\n",
    "\n",
    "Ud puede usar otras estrategias, pero deben ser con Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un objeto ``SimpleImputer``\n",
    "\n",
    "si = SimpleImputer(\n",
    "    missing_values=np.nan,  # los valores que faltan son del tipo ``np.nan`` (Pandas estándar)\n",
    "    strategy='constant',  # la estrategia elegida es cambiar el valor faltante por una constante (Ejemplo)\n",
    "    fill_value=0,  # la constante que se usará para completar los valores faltantes es un int64 = 0\n",
    "    verbose=0,\n",
    "    copy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarizando los valores numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-entrenando el modelo para definir el pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda de abajo se declara un objeto **Pipeline** de scikit-learn, donde es declarado como parametros *steps*, que es una lista de etapas a ejecutar el pipeline:\n",
    "\n",
    "    'paso_1_remove_cols'     - Transformación personalizada DropColumns\n",
    "    'paso_2_imputer'         - Transformación embebida de scikit-learn para remplazar los valores faltantes\n",
    "    'paso_3_standard_scaler'          - Transformación embebida de scikit-learn para escalar las variables numéricas\n",
    "    'su_modelo'              - Un árbol de desición simple\n",
    "    \n",
    "Note que pasamos como pasos las transformaciones instanciadas anteriormente, con nombres `rm_columns` y `si`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de nuestro para almacenamiento en Watson Machine Learning:\n",
    "my_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('paso_1_remove_cols', rm_columns),\n",
    "        ('paso_2_imputer', si),\n",
    "        ('paso_3_standard_scaler', sc),\n",
    "        ('su_modelo', DecisionTreeClassifier(max_depth=3)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En seguida ejecutaremos el método `fit()` del Pipeline, realizando el pré-procesamiento y el entrenamiento del modelo de una sola vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando el Pipeline (pre-procesamiento y entrenamiento del modelo)\n",
    "my_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Haciendo una predicción con el set de prueba\n",
    "\n",
    "y_pred = my_pipeline.predict(X_test)\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "group_names = ['Aprobado `Aceptado`', 'Refused `Sospechoso`', 'Refused `Aceptado`', 'Aprobado `Sospechoso`']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "accuracy  = np.trace(cf_matrix) / float(np.sum(cf_matrix))\n",
    "precision = cf_matrix[1,1] / sum(cf_matrix[:,1])\n",
    "recall    = cf_matrix[1,1] / sum(cf_matrix[1,:])\n",
    "f1_score  = 2*precision*recall / (precision + recall)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='')\n",
    "stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(accuracy, precision, recall, f1_score)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label' + stats_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precisión simple\n",
    "my_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos un Pipeline completo, con etapas de pre-procesamiento configuradas y tambien un modelo por Árbol de Desición entrenado, podemos realizar la integración con Watson Machine Learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encapsulando un Pipeline personalizado de Watson Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estableciendo conexión entre el cliente Python de WML y su instancia del servicio en la nube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblioteca Python con implementación de un cliente HTTP para la API de WML\n",
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las próximas celdas realizaran el despliegue del pipeline declarada en este notebook en WML. Solo prosiga si usted ya está satisfecho con su modelo y cree que ya es hora de hacer el despliegue de su solución.\n",
    "\n",
    "Copie las credenciales de su instancia de Watson Machine Learning en la variable de la celda de abajo.\n",
    "\n",
    "Es importante que la variable que contenga los valores de la credencial se llame ``wml_credentials`` para que las proximas celdas de este notebook se ejecuten corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando un objeto cliente de Watson Machine Learning a partir de las credenciales\n",
    "\n",
    "clientWML = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrayendo los detalles de su de Watson Machine Learning\n",
    "\n",
    "instance_details = clientWML.service_instance.get_details()\n",
    "print(json.dumps(instance_details, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¡¡ATENCIÓN!!**\n",
    "\n",
    "¡Este atento de los limites de consumo de su instancia de Watson Machine Learning!\n",
    "\n",
    "En caso de que acabe la capa gratuita, no sera posible evualuar su modelo (Pues es necesario para la realización de algunas llamadasal API con sus predicciones!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listando todos los artefatos almacenados en su WML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para listar todos los artefatos almacenados en su Watson Machine Learning, usted puede usar la seguinte función:\n",
    "\n",
    "    clientWML.repository.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listando todos los artefatos actualmente almacenados en su instancia de WML\n",
    "\n",
    "clientWML.repository.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATENCIÓN!, SI UD CORRE LAS CELDAS DE ABAJO TODOS LOS DESPLIEGUES ANTERIORS SERAN BORRADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Celda para borrar los Deployments:\n",
    "\n",
    "for uid in clientWML.deployments.get_uids():\n",
    "    if clientWML.deployments.get_details(uid)['entity']['name'] == 'deployment_meta_4' : \n",
    "        print('Deleted ' + clientWML.deployments.get_details(uid)['entity']['name'] )\n",
    "        clientWML.deployments.delete(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Celda para borrar todos los recursos:\n",
    "\n",
    "d = clientWML.repository.get_details()\n",
    "for k in d:\n",
    "    for res in d[k][\"resources\"]:\n",
    "        if res['entity']['name'] in ['package_meta_4', 'runtime_meta_4', 'pipeline_meta_4']:\n",
    "            clientWML.repository.delete(res[\"metadata\"][\"guid\"])\n",
    "            print('Deleted ' + res['entity']['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listando todos los artefatos actualmente almacenados en su instancia de WML\n",
    "\n",
    "clientWML.repository.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creando una nueva definición de paquete Python personalizado en WML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso para realizar su deploy y almacenar el código de las transformaciones personalizadas creadas por usted.\n",
    "\n",
    "Para esta etapa solo necesitamos el archivo .zip del paquete creado por usted (Que ya tenemos cargados en el Kernel!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de metadatos del paquete con las Transformaciones personalizadas\n",
    "pkg_meta = {\n",
    "    clientWML.runtimes.LibraryMetaNames.NAME: \"package_meta_4\",\n",
    "    clientWML.runtimes.LibraryMetaNames.DESCRIPTION: \"A custom sklearn transform package\",\n",
    "    clientWML.runtimes.LibraryMetaNames.FILEPATH: \"sklearn_transforms.zip\",  # Note que estamos utilizando o .zip criado anteriormente!\n",
    "    clientWML.runtimes.LibraryMetaNames.VERSION: \"1.0\",\n",
    "    clientWML.runtimes.LibraryMetaNames.PLATFORM: { \"name\": \"python\", \"versions\": [\"3.6\"] }\n",
    "}\n",
    "custom_package_details = clientWML.runtimes.store_library( pkg_meta )\n",
    "custom_package_uid = clientWML.runtimes.get_library_uid( custom_package_details )\n",
    "\n",
    "print(\"\\n Lista de artefactos de runtime almacenados en WML:\")\n",
    "clientWML.repository.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creando una nueva definición de runtime Python personalizado en WML\n",
    "\n",
    "El segundo paso es almacenar una definición de runtime Python para utilizar en nuestra biblioteca personalizada.\n",
    "\n",
    "Esto puede hacerse de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_meta = {\n",
    "    clientWML.runtimes.ConfigurationMetaNames.NAME: \"runtime_meta_4\",\n",
    "    clientWML.runtimes.ConfigurationMetaNames.DESCRIPTION: \"A Python runtime with custom sklearn Transforms\",\n",
    "    clientWML.runtimes.ConfigurationMetaNames.PLATFORM: {\n",
    "        \"name\": \"python\",\n",
    "        \"version\": \"3.6\"\n",
    "    },\n",
    "    clientWML.runtimes.ConfigurationMetaNames.LIBRARIES_UIDS: [ custom_package_uid ]\n",
    "}\n",
    "runtime_details = clientWML.runtimes.store( runtime_meta )\n",
    "custom_runtime_uid = clientWML.runtimes.get_uid( runtime_details )\n",
    "\n",
    "print(\"\\n Detalles del runtime almacenados:\")\n",
    "print(json.dumps(runtime_details, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listando todos los runtimes almacenados en su WML:\n",
    "clientWML.runtimes.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creando una nueva definición de Pipeline personalizado en WML\n",
    "\n",
    "Finalmente creando una definición (metadatos) para que nuestro Pipeline sea hospedada en WML.\n",
    "\n",
    "Definimos como parametros el nombre para el artefacto y el ID de runtime creado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meta = {\n",
    "    clientWML.repository.ModelMetaNames.NAME: 'pipeline_meta_4',\n",
    "    clientWML.repository.ModelMetaNames.DESCRIPTION: \"my pipeline for submission\",\n",
    "    clientWML.repository.ModelMetaNames.RUNTIME_UID: custom_runtime_uid\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En seguida llamamos el método para almacenar una nueva definición:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para almacenar una definición de Pipeline en WML\n",
    "stored_model_details = clientWML.repository.store_model(\n",
    "    model=my_pipeline,  # `my_pipeline` es la variable creada anteriormente que contiene nuestro Pipeline ya entrenado :)\n",
    "    meta_props=model_meta,  # Metadatos definidos en la celda anterior\n",
    "    training_data=None  # No altere este parametro\n",
    ")\n",
    "\n",
    "print(\"\\n Lista de artefatos almacenados en WML:\")\n",
    "clientWML.repository.list()\n",
    "\n",
    "# Datalles del modelo hospedado en Watson Machine Learning\n",
    "print(\"\\n Metadatos del modelo almacenado:\")\n",
    "print(json.dumps(stored_model_details, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizando un deployment de su modelo para consumo inmediato por otras aplicaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El deployment del modelo es finalmente realizado por medio del método ``deployments.create()``\n",
    "\n",
    "model_deployment_details = clientWML.deployments.create(\n",
    "    artifact_uid=stored_model_details[\"metadata\"][\"guid\"],  # No altere este parametro\n",
    "    name=\"deployment_meta_4\",\n",
    "    description=\"Desafio 4 MBTC\",\n",
    "    asynchronous=False,  # No altere este parametro\n",
    "    deployment_type='online',  # No altere este parametro\n",
    "    deployment_format='Core ML',  # No altere este parametro\n",
    "    meta_props=model_meta  # No altere este parametro\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probando el modelo hospedado en Watson Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperando la URL endpoint dl modelo hospedado en la celda anterior\n",
    "\n",
    "model_endpoint_url = clientWML.deployments.get_scoring_url(model_deployment_details)\n",
    "print(\"La URL de llamada de su API es: {}\".format(model_endpoint_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATENCIÓN: UD necesitará de la URL de arriba para entregar su modelo :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detalles del deployment realizado\n",
    "\n",
    "deployment_details = clientWML.deployments.get_details(\n",
    "    deployment_uid=model_deployment_details[\"metadata\"][\"guid\"]  # Este es el ID de su deployment!\n",
    ")\n",
    "\n",
    "print(\"Metadatos del deployment realizado: \\n\")\n",
    "print(json.dumps(deployment_details, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando una llamada de API para su modelo almacenado en WML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scoring_payload = {\n",
    "    'fields': [\n",
    "        'EFECTIVO',\n",
    "        'CXC',\n",
    "        'INVENTARIO',\n",
    "        'EQ_OFICINA',\n",
    "        'EQ_TRANSPORTE',\n",
    "        'TERRENOS_Y_CONSTRUCCIONES',\n",
    "        'CXP',\n",
    "        'CONTRIBUCIONES_X_PAGAR',\n",
    "        'ANTICIPOS_CTE',\n",
    "        'CAP_SOCIAL',\n",
    "        'UTILIDADES_ACUMULADAS',\n",
    "        'UTILIDAD_O_PERDIDA',\n",
    "        'TOTAL_VENTAS',\n",
    "        'TOTAL_COMPRAS',\n",
    "        'UTILIDAD_BRUTA',\n",
    "        'TOTAL_GASTOS',\n",
    "    ],\n",
    "    'values': [\n",
    "        [\n",
    "            968866.8993,\n",
    "            102102.000,\n",
    "            8539205.63,\n",
    "            3898282.548,\n",
    "            416873.3265,\n",
    "            1420050.089,\n",
    "            -629717.8548,\n",
    "            14613560.64,\n",
    "            7620711.462,\n",
    "            116647.7396,\n",
    "            1798064.624,\n",
    "            9535423.826,\n",
    "            3657339.603,\n",
    "            770284.5004,\n",
    "            -102101.201,\n",
    "            -711032.0155\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n Payload de datos a ser clasificado:\")\n",
    "print(json.dumps(scoring_payload, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = clientWML.deployments.score(\n",
    "    model_endpoint_url,\n",
    "    scoring_payload\n",
    ")\n",
    "\n",
    "print(\"\\n Resultados:\")\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## ¡Felicitaciones! \n",
    "\n",
    "Si todo fue ejecutado sin errores, ¡usted ya tiene un predictor basado en clasificacíon binaria encapsulado como una API REST!\n",
    "\n",
    "Para enviar su solución, accede a la página:\n",
    "\n",
    "# https://compusoluciones.maratona.dev\n",
    "\n",
    "Usted necesitará del endpoint url de su modelo y las credenciales de WML :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
